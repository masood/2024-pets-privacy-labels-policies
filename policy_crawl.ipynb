{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "YZX8XKA_nodZ",
        "Yrys_MStpFLx",
        "mLKXXPDWsIfk",
        "IalyskcNsS3R",
        "yp3OJiHsyLbu",
        "-TG6KLgp1pnN"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Extracting Data Collection Practices from Privacy Labels (Demo)"
      ],
      "metadata": {
        "id": "YZX8XKA_nodZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once we collect the URL of an app's privacy policy from the App Store, we can visit this URL and parse its text contents.\n",
        "\n",
        "In this demo, we provide code to visit example policies and clean the response text. We then independently classify text segments (or paragraphs) and interpret the classifier outputs into privacy labels."
      ],
      "metadata": {
        "id": "eYoQmMVfn0qP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ğŸ’¡ This demo needs to be run on GPUs. To do so, navigate to the notebook's menu at the top, `Runtime > Change runtime type` and select `T4 GPU`."
      ],
      "metadata": {
        "id": "8ivgUiNdow9C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install readabilipy langdetect beautifulsoup4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mVPM_9NpWnv",
        "outputId": "d0001036-81d9-4053-8800-035167e8585c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: readabilipy in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.10/dist-packages (1.0.9)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: html5lib in /usr/local/lib/python3.10/dist-packages (from readabilipy) (1.1)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from readabilipy) (4.9.4)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from readabilipy) (2024.5.15)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect) (1.16.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.5)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from html5lib->readabilipy) (0.5.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import requests\n",
        "from readabilipy import simple_json_from_html_string\n",
        "import random\n",
        "import string\n",
        "from langdetect import detect\n",
        "from bs4 import BeautifulSoup\n",
        "import torch\n",
        "from transformers import AutoTokenizer"
      ],
      "metadata": {
        "id": "Ho98CY3hpgPQ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Crawl Privacy Policy"
      ],
      "metadata": {
        "id": "Yrys_MStpFLx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Functions to Clean Extracted Text"
      ],
      "metadata": {
        "id": "mLKXXPDWsIfk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_out_headings(policy_text, html_content):\n",
        "    def getTextFromTag(html_string, tag):\n",
        "        header_lines = []\n",
        "        soup = BeautifulSoup(html_string, 'html.parser')\n",
        "        for element in soup.find_all(tag):\n",
        "            header_lines.append(element.text)\n",
        "        return header_lines\n",
        "    policy_headings_text = getTextFromTag(html_content, ['h1', 'h2', 'h3', 'h4', 'h5', 'h6'])\n",
        "    policy_text_filtered_headers = [x for x in policy_text if x not in policy_headings_text]\n",
        "    return policy_text_filtered_headers\n",
        "\n",
        "def merge_lists(policy_text):\n",
        "    policy_text_filtered_lists = []\n",
        "    for line_index in range(len(policy_text)):\n",
        "        if policy_text[line_index][-1] == ',':\n",
        "            whole_segment = policy_text[line_index].split('*')\n",
        "            avg_len = 0\n",
        "            for list_element in whole_segment:\n",
        "                avg_len += len(list_element.split())\n",
        "            avg_len = avg_len / len(whole_segment)\n",
        "            if (avg_len >= 20):\n",
        "                for list_element in whole_segment:\n",
        "                    policy_text_filtered_lists.append(list_element.strip())\n",
        "            else:\n",
        "                if (len(policy_text_filtered_lists) == 0):\n",
        "                    policy_text_filtered_lists = [policy_text[line_index]]\n",
        "                else:\n",
        "                    policy_text_filtered_lists[-1] += policy_text[line_index]\n",
        "        else:\n",
        "            policy_text_filtered_lists.append(policy_text[line_index])\n",
        "    return policy_text_filtered_lists\n",
        "\n",
        "def remove_short_sentences(policy_text):\n",
        "    policy_text_filtered_lists = []\n",
        "    for line_index in range(len(policy_text)):\n",
        "        num_words = len(policy_text[line_index].split(' '))\n",
        "        if (num_words >= 20):\n",
        "            policy_text_filtered_lists.append(policy_text[line_index].strip())\n",
        "    return policy_text_filtered_lists\n",
        "\n",
        "def find_and_remove_large_string(strings):\n",
        "    def preprocess_string(s):\n",
        "        # Convert to lowercase and remove punctuation\n",
        "        return s.lower().translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "    def is_substring_found(substring, large_string):\n",
        "        # Check if 90% of the substring is in the large string\n",
        "        substring_length = len(substring)\n",
        "        match_length = int(substring_length * 0.9)\n",
        "\n",
        "        for i in range(len(large_string) - match_length + 1):\n",
        "            if substring[:match_length] in large_string[i:i+match_length]:\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "    def contains_all_substrings(large_string, substrings):\n",
        "        count = 0\n",
        "        for substring in substrings:\n",
        "            if is_substring_found(substring, large_string):\n",
        "                count += 1\n",
        "        return count / len(substrings) >= 0.50\n",
        "\n",
        "    preprocessed_strings = [preprocess_string(s) for s in strings]\n",
        "\n",
        "    for large_string in strings:\n",
        "        preprocessed_large_string = preprocess_string(large_string)\n",
        "\n",
        "        # Check if this string contains 90% of the other preprocessed strings\n",
        "        other_strings = [s for s in preprocessed_strings if s != preprocessed_large_string]\n",
        "        if contains_all_substrings(preprocessed_large_string, other_strings):\n",
        "            strings.remove(large_string)\n",
        "            return strings\n",
        "\n",
        "    return strings"
      ],
      "metadata": {
        "id": "8MQ7JEW0sScI"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " ### Functions to Viait URL and Collect Policy Text"
      ],
      "metadata": {
        "id": "IalyskcNsS3R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_policy_text(privacy_policy_url):\n",
        "    user_agents = [\n",
        "        \"Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; SV1; .NET CLR 1.1.4322)\",\n",
        "        \"Mozilla/5.0 (Windows NT 6.1; WOW64; Trident/7.0; rv:11.0) like Gecko\",\n",
        "        \"Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1)\",\n",
        "        \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10.16; rv:86.0) Gecko/20100101 Firefox/86.0\"\n",
        "    ]\n",
        "\n",
        "    request_headers = {\n",
        "        \"Accept\": \"text/html\",\n",
        "        \"Connection\": \"keep-alive\",\n",
        "        \"Content-Type\": \"application/x-www-form-urlencoded; charset=UTF-8\",\n",
        "        \"Origin\": \"https://apps.apple.com\",\n",
        "        \"Referer\": \"https://apps.apple.com\",\n",
        "        \"User-Agent\": random.choice(user_agents),\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.get(privacy_policy_url, headers=request_headers, timeout=15)\n",
        "    except:\n",
        "        print(\"Error with Request\")\n",
        "        return\n",
        "\n",
        "    if response.status_code >= 200 and response.status_code < 400:\n",
        "        try:\n",
        "            html_content = response.text\n",
        "        except:\n",
        "            print(\"Error extracting HTML content\")\n",
        "            return\n",
        "\n",
        "        try:\n",
        "            article = simple_json_from_html_string(html_content, use_readability=True)\n",
        "        except:\n",
        "            try:\n",
        "                article = simple_json_from_html_string(html_content, use_readability=False)\n",
        "            except:\n",
        "                print(\"Error parsing text from HTML content\")\n",
        "\n",
        "        if 'plain_text' in article and article['plain_text']:\n",
        "            return list(set(list(map(lambda x: x['text'], article['plain_text'])))), article['content']"
      ],
      "metadata": {
        "id": "04js4j52nzt2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Classification Demo: Extract Data Collection Practices from Policy Segments"
      ],
      "metadata": {
        "id": "bV-SzrE5xg7C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Pre-trained Classification Models"
      ],
      "metadata": {
        "id": "yp3OJiHsyLbu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf PrivBERT-*"
      ],
      "metadata": {
        "id": "aCcHpDYG0Ms9"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git lfs install\n",
        "!git clone https://huggingface.co/masoodali/PrivBERT-Main"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Spq3bEKxrUo",
        "outputId": "1cb9f39d-46c9-4059-af9f-d871b1dbfb40"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Git LFS initialized.\n",
            "Cloning into 'PrivBERT-Main'...\n",
            "remote: Enumerating objects: 14, done.\u001b[K\n",
            "remote: Counting objects: 100% (10/10), done.\u001b[K\n",
            "remote: Compressing objects: 100% (10/10), done.\u001b[K\n",
            "remote: Total 14 (delta 1), reused 0 (delta 0), pack-reused 4 (from 1)\u001b[K\n",
            "Unpacking objects: 100% (14/14), 1.09 MiB | 4.81 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git lfs install\n",
        "!git clone https://huggingface.co/masoodali/PrivBERT-Purpose"
      ],
      "metadata": {
        "id": "IpI8EF-wzwWP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fea5b80-a565-43a1-9fae-c42d67c80460"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Git LFS initialized.\n",
            "Cloning into 'PrivBERT-Purpose'...\n",
            "remote: Enumerating objects: 14, done.\u001b[K\n",
            "remote: Counting objects: 100% (10/10), done.\u001b[K\n",
            "remote: Compressing objects: 100% (10/10), done.\u001b[K\n",
            "remote: Total 14 (delta 1), reused 0 (delta 0), pack-reused 4 (from 1)\u001b[K\n",
            "Unpacking objects: 100% (14/14), 1.09 MiB | 2.36 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git lfs install\n",
        "!git clone https://huggingface.co/masoodali/PrivBERT-Identifiability"
      ],
      "metadata": {
        "id": "9_7v3nJEzy6_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffff391f-5d0f-4186-f9b9-6e882359f33f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Git LFS initialized.\n",
            "Cloning into 'PrivBERT-Identifiability'...\n",
            "remote: Enumerating objects: 12, done.\u001b[K\n",
            "remote: Counting objects: 100% (8/8), done.\u001b[K\n",
            "remote: Compressing objects: 100% (8/8), done.\u001b[K\n",
            "remote: Total 12 (delta 0), reused 0 (delta 0), pack-reused 4 (from 1)\u001b[K\n",
            "Unpacking objects: 100% (12/12), 1.08 MiB | 1.44 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git lfs install\n",
        "!git clone https://huggingface.co/masoodali/PrivBERT-Does-or-Does-Not"
      ],
      "metadata": {
        "id": "rWPXITayz1Bq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3346c963-ce54-416f-f276-de01ade4f0e0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Git LFS initialized.\n",
            "Cloning into 'PrivBERT-Does-or-Does-Not'...\n",
            "remote: Enumerating objects: 12, done.\u001b[K\n",
            "remote: Counting objects: 100% (8/8), done.\u001b[K\n",
            "remote: Compressing objects: 100% (8/8), done.\u001b[K\n",
            "remote: Total 12 (delta 0), reused 0 (delta 0), pack-reused 4 (from 1)\u001b[K\n",
            "Unpacking objects: 100% (12/12), 1.08 MiB | 1.62 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git lfs install\n",
        "!git clone https://huggingface.co/masoodali/PrivBERT-Personal-Information-Type"
      ],
      "metadata": {
        "id": "j1SYS7Etz4lg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45fa12ac-b76c-4937-8c69-4e00d43f8fcc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Git LFS initialized.\n",
            "Cloning into 'PrivBERT-Personal-Information-Type'...\n",
            "remote: Enumerating objects: 15, done.\u001b[K\n",
            "remote: Counting objects: 100% (11/11), done.\u001b[K\n",
            "remote: Compressing objects: 100% (11/11), done.\u001b[K\n",
            "remote: Total 15 (delta 1), reused 0 (delta 0), pack-reused 4 (from 1)\u001b[K\n",
            "Unpacking objects: 100% (15/15), 1.09 MiB | 5.14 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git lfs install\n",
        "!git clone https://huggingface.co/masoodali/PrivBERT-Action-First-Party"
      ],
      "metadata": {
        "id": "kSJbfHhfz5Ss",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27ca2047-6b8e-452a-a11f-4db2b9735879"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Git LFS initialized.\n",
            "Cloning into 'PrivBERT-Action-First-Party'...\n",
            "remote: Enumerating objects: 12, done.\u001b[K\n",
            "remote: Counting objects: 100% (8/8), done.\u001b[K\n",
            "remote: Compressing objects: 100% (8/8), done.\u001b[K\n",
            "remote: Total 12 (delta 0), reused 0 (delta 0), pack-reused 4 (from 1)\u001b[K\n",
            "Unpacking objects: 100% (12/12), 1.08 MiB | 1.42 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git lfs install\n",
        "!git clone https://huggingface.co/masoodali/PrivBERT-Action-Third-Party"
      ],
      "metadata": {
        "id": "C-04AiN9z9dM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eea1753f-b786-43cd-dcf2-c0b5b0cc6c3e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Git LFS initialized.\n",
            "Cloning into 'PrivBERT-Action-Third-Party'...\n",
            "remote: Enumerating objects: 12, done.\u001b[K\n",
            "remote: Counting objects: 100% (8/8), done.\u001b[K\n",
            "remote: Compressing objects: 100% (8/8), done.\u001b[K\n",
            "remote: Total 12 (delta 0), reused 0 (delta 0), pack-reused 4 (from 1)\u001b[K\n",
            "Unpacking objects: 100% (12/12), 1.08 MiB | 4.83 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git lfs install\n",
        "!git clone https://huggingface.co/masoodali/PrivBERT-Audience-Type"
      ],
      "metadata": {
        "id": "k1_kPQ8Jz_SV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5942260b-a163-4aea-bbfb-9b4836427a7e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Git LFS initialized.\n",
            "Cloning into 'PrivBERT-Audience-Type'...\n",
            "remote: Enumerating objects: 12, done.\u001b[K\n",
            "remote: Counting objects: 100% (8/8), done.\u001b[K\n",
            "remote: Compressing objects: 100% (8/8), done.\u001b[K\n",
            "remote: Total 12 (delta 0), reused 0 (delta 0), pack-reused 4 (from 1)\u001b[K\n",
            "Unpacking objects: 100% (12/12), 1.08 MiB | 2.87 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import cuda\n",
        "cuda.empty_cache()\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "DM8YaclNzDpp"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "majority_model = torch.load(\"PrivBERT-Main/pytorch-privbert.bin\")\n",
        "majority_tokenizer = AutoTokenizer.from_pretrained(\"PrivBERT-Main/\")\n",
        "\n",
        "identifiability_model = torch.load(\"PrivBERT-Identifiability/pytorch-privbert.bin\")\n",
        "identifiability_tokenizer = AutoTokenizer.from_pretrained(\"PrivBERT-Identifiability/\")\n",
        "\n",
        "does_model = torch.load(\"PrivBERT-Does-or-Does-Not/pytorch-privbert.bin\")\n",
        "does_tokenizer = AutoTokenizer.from_pretrained(\"PrivBERT-Does-or-Does-Not/\")\n",
        "\n",
        "purpose_model = torch.load(\"PrivBERT-Purpose/pytorch-privbert.bin\")\n",
        "purpose_tokenizer = AutoTokenizer.from_pretrained(\"PrivBERT-Purpose/\")\n",
        "\n",
        "information_model = torch.load(\"PrivBERT-Personal-Information-Type/pytorch-privbert.bin\")\n",
        "information_tokenizer = AutoTokenizer.from_pretrained(\"PrivBERT-Personal-Information-Type/\")\n",
        "\n",
        "action_first_model = torch.load(\"PrivBERT-Action-First-Party/pytorch-privbert.bin\")\n",
        "action_first_tokenizer = AutoTokenizer.from_pretrained(\"PrivBERT-Action-First-Party/\")\n",
        "\n",
        "action_third_model = torch.load(\"PrivBERT-Action-Third-Party/pytorch-privbert.bin\")\n",
        "action_third_tokenizer = AutoTokenizer.from_pretrained(\"PrivBERT-Action-Third-Party/\")\n",
        "\n",
        "audience_model = torch.load(\"PrivBERT-Audience-Type/pytorch-privbert.bin\")\n",
        "audience_tokenizer = AutoTokenizer.from_pretrained(\"PrivBERT-Audience-Type/\")"
      ],
      "metadata": {
        "id": "SwAUG7npzHvb"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classify Extracted Policy Segments"
      ],
      "metadata": {
        "id": "-TG6KLgp1pnN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_classifier_result(classifier_result, segment_text):\n",
        "    return {\n",
        "        'segment_text': segment_text,\n",
        "        'action_first_mobile': 1 if classifier_result['action_first'][0][0] > 0.5 else 0,\n",
        "        'action_first_website': 1 if classifier_result['action_first'][0][1] > 0.5 else 0,\n",
        "        'action_third_website': 1 if  classifier_result['action_third'][0][0] > 0.5 else 0,\n",
        "        'action_third_see': 1 if classifier_result['action_third'][0][1] > 0.5 else 0,\n",
        "        'children': 1 if classifier_result['audience'][0][0] > 0.5 else 0,\n",
        "        'does': 1 if classifier_result['does'][0][0] > 0.5 else 0,\n",
        "        'does_not': 1 if classifier_result['does'][0][1] > 0.5 else 0,\n",
        "        'aggregated': 1 if classifier_result['identifiability'][0][0] > 0.5 else 0,\n",
        "        'identifiable': 1 if classifier_result['identifiability'][0][1] > 0.5 else 0,\n",
        "        'main_first': 1 if classifier_result['main'][0][0] > 0.5 else 0,\n",
        "        'main_third': 1 if classifier_result['main'][0][1] > 0.5 else 0,\n",
        "        'main_audience': 1 if classifier_result['main'][0][5] > 0.5 else 0,\n",
        "        'computer_info': 1 if classifier_result['information'][0][0] > 0.5 else 0,\n",
        "        'contact': 1 if classifier_result['information'][0][1] > 0.5 else 0,\n",
        "        'cookies': 1 if classifier_result['information'][0][2] > 0.5 else 0,\n",
        "        'demographic': 1 if classifier_result['information'][0][3] > 0.5 else 0,\n",
        "        'financial': 1 if classifier_result['information'][0][4] > 0.5 else 0,\n",
        "        'generic': 1 if classifier_result['information'][0][5] > 0.5 else 0,\n",
        "        'health': 1 if classifier_result['information'][0][6] > 0.5 else 0,\n",
        "        'ip': 1 if classifier_result['information'][0][7] > 0.5 else 0,\n",
        "        'location': 1 if classifier_result['information'][0][8] > 0.5 else 0,\n",
        "        'personal_id': 1 if classifier_result['information'][0][9] > 0.5 else 0,\n",
        "        'social': 1 if classifier_result['information'][0][10] > 0.5 else 0,\n",
        "        'survey': 1 if classifier_result['information'][0][11] > 0.5 else 0,\n",
        "        'online_activities': 1 if classifier_result['information'][0][12] > 0.5 else 0,\n",
        "        'profile': 1 if classifier_result['information'][0][13] > 0.5 else 0,\n",
        "        'info_unspecified': 1 if classifier_result['information'][0][14] > 0.5 else 0,\n",
        "        'additional': 1 if classifier_result['purpose'][0][0] > 0.5 else 0,\n",
        "        'advertising': 1 if classifier_result['purpose'][0][1] > 0.5 else 0,\n",
        "        'analytics': 1 if classifier_result['purpose'][0][2] > 0.5 else 0,\n",
        "        'basic': 1 if classifier_result['purpose'][0][3] > 0.5 else 0,\n",
        "        'legal': 1 if classifier_result['purpose'][0][4] > 0.5 else 0,\n",
        "        'marketing': 1 if classifier_result['purpose'][0][5] > 0.5 else 0,\n",
        "        'merger': 1 if classifier_result['purpose'][0][6] > 0.5 else 0,\n",
        "        'personalization': 1 if classifier_result['purpose'][0][7] > 0.5 else 0,\n",
        "        'operation': 1 if classifier_result['purpose'][0][8] > 0.5 else 0,\n",
        "        'purpose_unspecified': 1 if classifier_result['purpose'][0][9] > 0.5 else 0\n",
        "    }"
      ],
      "metadata": {
        "id": "JzhmasMq27cQ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_policy(policy_segments):\n",
        "    def classify_segment(segment, model, tokenizer):\n",
        "        inputs = tokenizer.encode_plus(\n",
        "            segment,\n",
        "            add_special_tokens=True,\n",
        "            max_length=512,\n",
        "            pad_to_max_length=True,\n",
        "            return_token_type_ids=True,\n",
        "            return_tensors = 'pt'\n",
        "        )\n",
        "        ids = inputs['input_ids'].to(device, dtype = torch.long)\n",
        "        mask = inputs['attention_mask'].to(device, dtype = torch.long)\n",
        "        token_type_ids = inputs['token_type_ids'].to(device, dtype = torch.long)\n",
        "        outputs = model(ids, mask, token_type_ids)\n",
        "        outputs = outputs.logits\n",
        "        fin_outputs=[]\n",
        "        fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
        "        return fin_outputs\n",
        "\n",
        "    classifier_results_raw = []\n",
        "    for policy_segment in policy_segments:\n",
        "        classifier_results_raw.append({\n",
        "            'segment' : policy_segment,\n",
        "            'main': classify_segment(policy_segment, majority_model, majority_tokenizer),\n",
        "            'identifiability': classify_segment(policy_segment, identifiability_model, identifiability_tokenizer),\n",
        "            'does': classify_segment(policy_segment, does_model, does_tokenizer),\n",
        "            'purpose': classify_segment(policy_segment, purpose_model, purpose_tokenizer),\n",
        "            'information': classify_segment(policy_segment, information_model, information_tokenizer),\n",
        "            'action_first': classify_segment(policy_segment, action_first_model, action_first_tokenizer),\n",
        "            'action_third': classify_segment(policy_segment, action_third_model, action_third_tokenizer),\n",
        "            'audience': classify_segment(policy_segment, audience_model, audience_tokenizer),\n",
        "        })\n",
        "\n",
        "    classifier_results_parsed = [parse_classifier_result(classifier_results_raw[i], policy_segments[i]) for i in range(len(policy_segments))]\n",
        "\n",
        "    return classifier_results_parsed"
      ],
      "metadata": {
        "id": "wxjm7Tsw1g9x"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Privacy Label from Privacy Policy"
      ],
      "metadata": {
        "id": "lnYOamq87-Qr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sensitive_info_keywords = ['racial', 'ethnic', 'ethnicity', 'sexual orientation', 'sexual preference', 'pregnancy', 'pregnant', 'childbirth', 'child birth', 'child-birth', 'disability', 'religion', 'religious', 'religious belief', 'trade union', 'union member', 'politics', 'political', 'genetic', 'genetic information', 'biometric']\n",
        "def classifier_to_label(classifier_results):\n",
        "    generated_privacy_label = []\n",
        "    for classifier_result in classifier_results:\n",
        "        segment_privacy_label = {\n",
        "            'privacy_type_track': 1 if classifier_result['does'] == 1 and ((classifier_result['main_third'] == 1 and not (classifier_result['action_third_website'] == 0 and classifier_result['action_third_see'] == 1)) and classifier_result['advertising'] == 1) else 0,\n",
        "            'privacy_type_linked': 1 if classifier_result['does'] == 1 and (((classifier_result['main_first'] == 1 and not (classifier_result['action_first_mobile'] == 0 and classifier_result['action_first_website'] == 1)) or (classifier_result['main_third'] == 1 and not (classifier_result['action_third_website'] == 0 and classifier_result['action_third_see'] == 1))) and classifier_result['identifiable'] == 1) else 0,\n",
        "            'privacy_type_not_linked': 1 if classifier_result['does'] == 1 and (((classifier_result['main_first'] == 1 and not (classifier_result['action_first_mobile'] == 0 and classifier_result['action_first_website'] == 1)) or (classifier_result['main_third'] == 1 and not (classifier_result['action_third_website'] == 0 and classifier_result['action_third_see'] == 1))) and classifier_result['aggregated'] == 1) else 0,\n",
        "            'privacy_type_not_collected': 1 if (((classifier_result['main_first'] == 1 and not (classifier_result['action_first_mobile'] == 0 and classifier_result['action_first_website'] == 1)) or (classifier_result['main_third'] == 1 and not (classifier_result['action_third_website'] == 0 and classifier_result['action_third_see'] == 1))) and classifier_result['does'] == 0 and classifier_result['does_not'] == 1) else 0,\n",
        "            'purpose_third_party_advertising': 1 if classifier_result['does'] == 1 and ((classifier_result['main_third'] == 1 and not (classifier_result['action_third_website'] == 0 and classifier_result['action_third_see'] == 1)) and classifier_result['advertising'] == 1) else 0,\n",
        "            'purpose_developer_advertising_marketing': 1 if classifier_result['does'] == 1 and ((classifier_result['main_first'] == 1 and not (classifier_result['action_first_mobile'] == 0 and classifier_result['action_first_website'] == 1)) and classifier_result['advertising'] == 1) else 0,\n",
        "            'purpose_analytics': 1 if classifier_result['does'] == 1 and (((classifier_result['main_first'] == 1 and not (classifier_result['action_first_mobile'] == 0 and classifier_result['action_first_website'] == 1)) or (classifier_result['main_third'] == 1 and not (classifier_result['action_third_website'] == 0 and classifier_result['action_third_see'] == 1))) and classifier_result['analytics'] == 1) else 0,\n",
        "            'purpose_product_personalization': 1 if classifier_result['does'] == 1 and (((classifier_result['main_first'] == 1 and not (classifier_result['action_first_mobile'] == 0 and classifier_result['action_first_website'] == 1)) or (classifier_result['main_third'] == 1 and not (classifier_result['action_third_website'] == 0 and classifier_result['action_third_see'] == 1))) and classifier_result['personalization'] == 1) else 0,\n",
        "            'purpose_app_functionality': 1 if classifier_result['does'] == 1 and (((classifier_result['main_first'] == 1 and not (classifier_result['action_first_mobile'] == 0 and classifier_result['action_first_website'] == 1)) == 1 or (classifier_result['main_third'] == 1 and not (classifier_result['action_third_website'] == 0 and classifier_result['action_third_see'] == 1))) and (classifier_result['basic'] == 1 or classifier_result['additional'] == 1 or classifier_result['operation'] == 1)) else 0,\n",
        "            'purpose_other':  1 if classifier_result['does'] == 1 and (((classifier_result['main_first'] == 1 and not (classifier_result['action_first_mobile'] == 0 and classifier_result['action_first_website'] == 1)) or (classifier_result['main_third'] == 1 and not (classifier_result['action_third_website'] == 0 and classifier_result['action_third_see'] == 1))) and (classifier_result['merger'] == 1 or classifier_result['legal'] == 1 or classifier_result['purpose_unspecified'] == 1)) else 0,\n",
        "            'data_category_contact_info': 1 if classifier_result['does'] == 1 and (((classifier_result['main_first'] == 1 and not (classifier_result['action_first_mobile'] == 0 and classifier_result['action_first_website'] == 1)) or (classifier_result['main_third'] == 1 and not (classifier_result['action_third_website'] == 0 and classifier_result['action_third_see'] == 1))) and classifier_result['contact'] == 1) else 0,\n",
        "            'data_category_health_fitness': 1 if classifier_result['does'] == 1 and (((classifier_result['main_first'] == 1 and not (classifier_result['action_first_mobile'] == 0 and classifier_result['action_first_website'] == 1)) or (classifier_result['main_third'] == 1 and not (classifier_result['action_third_website'] == 0 and classifier_result['action_third_see'] == 1))) and classifier_result['health'] == 1) else 0,\n",
        "            'data_category_financial_info': 1 if classifier_result['does'] == 1 and (((classifier_result['main_first'] == 1 and not (classifier_result['action_first_mobile'] == 0 and classifier_result['action_first_website'] == 1)) or (classifier_result['main_third'] == 1 and not (classifier_result['action_third_website'] == 0 and classifier_result['action_third_see'] == 1))) and classifier_result['financial'] == 1) else 0,\n",
        "            'data_category_location': 1 if classifier_result['does'] == 1 and (((classifier_result['main_first'] == 1 and not (classifier_result['action_first_mobile'] == 0 and classifier_result['action_first_website'] == 1)) or (classifier_result['main_third'] == 1 and not (classifier_result['action_third_website'] == 0 and classifier_result['action_third_see'] == 1))) and classifier_result['location'] == 1) else 0,\n",
        "            'data_category_sensitive': 1 if classifier_result['does'] == 1 and (((classifier_result['main_first'] == 1 and not (classifier_result['action_first_mobile'] == 0 and classifier_result['action_first_website'] == 1)) or (classifier_result['main_third'] == 1 and not (classifier_result['action_third_website'] == 0 and classifier_result['action_third_see'] == 1))) and (classifier_result['demographic'] == 1 or any (sensitive_keyword in classifier_result['segment_text'].lower() for sensitive_keyword in sensitive_info_keywords))) else 0,\n",
        "            'data_category_contacts': 1 if classifier_result['does'] == 1 and (((classifier_result['main_first'] == 1 and not (classifier_result['action_first_mobile'] == 0 and classifier_result['action_first_website'] == 1)) or (classifier_result['main_third'] == 1 and not (classifier_result['action_third_website'] == 0 and classifier_result['action_third_see'] == 1))) and ((classifier_result['social'] == 1 and any (contact_keyword in classifier_result['segment_text'].lower() for contact_keyword in ['contact', 'friend'])) or any (contact_keyword in classifier_result['segment_text'].lower() for contact_keyword in ['phone book', 'address book']))) else 0,\n",
        "            'data_category_user_content': 1 if classifier_result['does'] == 1 and (((classifier_result['main_first'] == 1 and not (classifier_result['action_first_mobile'] == 0 and classifier_result['action_first_website'] == 1)) or (classifier_result['main_third'] == 1 and not (classifier_result['action_third_website'] == 0 and classifier_result['action_third_see'] == 1))) and (classifier_result['profile'] == 1 or classifier_result['social'] == 1)) else 0,\n",
        "            'data_category_browsing_history': 1 if classifier_result['does'] == 1 and ((classifier_result['main_third'] == 1 and not (classifier_result['action_third_website'] == 0 and classifier_result['action_third_see'] == 1)) and classifier_result['online_activities'] == 1) else 0,\n",
        "            'data_category_search_history': 1 if classifier_result['does'] == 1 and ((classifier_result['main_first'] == 1 and not (classifier_result['action_first_mobile'] == 0 and classifier_result['action_first_website'] == 1)) and (classifier_result['online_activities'] == 1 and 'search' in classifier_result['segment_text'].lower())) else 0,\n",
        "            'data_category_identifiers': 1 if classifier_result['does'] == 1 and (((classifier_result['main_first'] == 1 and not (classifier_result['action_first_mobile'] == 0 and classifier_result['action_first_website'] == 1)) or (classifier_result['main_third'] == 1 and not (classifier_result['action_third_website'] == 0 and classifier_result['action_third_see'] == 1))) and (classifier_result['cookies'] == 1 or classifier_result['ip'] == 1)) else 0,\n",
        "            'data_category_purchases': 1 if classifier_result['does'] == 1 and (((classifier_result['main_first'] == 1 and not (classifier_result['action_first_mobile'] == 0 and classifier_result['action_first_website'] == 1)) or (classifier_result['main_third'] == 1 and not (classifier_result['action_third_website'] == 0 and classifier_result['action_third_see'] == 1))) and (classifier_result['financial'] == 1 and classifier_result['online_activities'] == 1)) else 0,\n",
        "            'data_category_usage_data': 1 if classifier_result['does'] == 1 and (((classifier_result['main_first'] == 1 and not (classifier_result['action_first_mobile'] == 0 and classifier_result['action_first_website'] == 1)) or (classifier_result['main_third'] == 1 and not (classifier_result['action_third_website'] == 0 and classifier_result['action_third_see'] == 1))) and classifier_result['online_activities'] == 1) else 0,\n",
        "            'data_category_diagnostics': 1 if classifier_result['does'] == 1 and (((classifier_result['main_first'] == 1 and not (classifier_result['action_first_mobile'] == 0 and classifier_result['action_first_website'] == 1)) or (classifier_result['main_third'] == 1 and not (classifier_result['action_third_website'] == 0 and classifier_result['action_third_see'] == 1))) and (classifier_result['computer_info'] == 1 or classifier_result['ip'] == 1)) else 0\n",
        "        }\n",
        "\n",
        "        if not set(list(segment_privacy_label.values())) == {0}:\n",
        "            generated_privacy_label.append(segment_privacy_label)\n",
        "    return generated_privacy_label"
      ],
      "metadata": {
        "id": "HsxDJaeJ8EX6"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Putting it all Together"
      ],
      "metadata": {
        "id": "7jR-kwGKAWte"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "privacy_policy_urls = {\n",
        "    'som': 'https://www.som.org.uk/privacy-and-cookie-policy'\n",
        "}"
      ],
      "metadata": {
        "id": "xHv7CP3b_Xfq"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "policy_segments, html_content = get_policy_text(privacy_policy_urls['som'])\n",
        "policy_segments = merge_lists(policy_segments)\n",
        "policy_segments = filter_out_headings(policy_segments, html_content)\n",
        "policy_segments = remove_short_sentences(policy_segments)\n",
        "policy_segments = find_and_remove_large_string(policy_segments)"
      ],
      "metadata": {
        "id": "jymAiglQ_HHU"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier_results = classify_policy(policy_segments)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KDz5sRj_JcF",
        "outputId": "9cb40cd9-36c0-4f41-9b36-85ef0d8f2226"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2699: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generated_label = classifier_to_label(classifier_results)\n",
        "generated_label"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVEO2WTt80YS",
        "outputId": "6ae02dd0-7be8-467f-b626-8d14d3235e38"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'privacy_type_track': 1,\n",
              "  'privacy_type_linked': 1,\n",
              "  'privacy_type_not_linked': 0,\n",
              "  'privacy_type_not_collected': 0,\n",
              "  'purpose_third_party_advertising': 1,\n",
              "  'purpose_developer_advertising_marketing': 0,\n",
              "  'purpose_analytics': 0,\n",
              "  'purpose_product_personalization': 0,\n",
              "  'purpose_app_functionality': 1,\n",
              "  'purpose_other': 0,\n",
              "  'data_category_contact_info': 0,\n",
              "  'data_category_health_fitness': 0,\n",
              "  'data_category_financial_info': 0,\n",
              "  'data_category_location': 0,\n",
              "  'data_category_sensitive': 0,\n",
              "  'data_category_contacts': 0,\n",
              "  'data_category_user_content': 0,\n",
              "  'data_category_browsing_history': 0,\n",
              "  'data_category_search_history': 0,\n",
              "  'data_category_identifiers': 1,\n",
              "  'data_category_purchases': 0,\n",
              "  'data_category_usage_data': 0,\n",
              "  'data_category_diagnostics': 0}]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    }
  ]
}